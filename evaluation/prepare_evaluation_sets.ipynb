{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather and Preprocess Valid/Test Sets for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import biotite.structure.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from na_eval_utils import (\n",
    "    read_cluster_ids_text_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exclusive_cluster_subset(dataset_df, \n",
    "                                 cluster_ids_column_name, \n",
    "                                 dataset_cluster_ids):\n",
    "    \"\"\"\n",
    "    Get a subset of the dataset dataframe where the cluster ids in the\n",
    "    specified column are all in the provided cluster ids for the dataset.\n",
    "    \"\"\"\n",
    "    # Subset the dataframe to only include rows where all cluster ids\n",
    "    # are in the provided cluster ids.\n",
    "    dataset_df_subset = dataset_df[\n",
    "        dataset_df[cluster_ids_column_name].apply(\n",
    "            lambda cluster_ids_str: all(\n",
    "                [cluster_id in dataset_cluster_ids for cluster_id in ast.literal_eval(cluster_ids_str)]\n",
    "            )\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    return dataset_df_subset\n",
    "\n",
    "def get_length_subset(dataset_df,\n",
    "                      max_length,\n",
    "                      min_length):\n",
    "    \"\"\"\n",
    "    Get a subset of the dataset dataframe where the assembly lengths\n",
    "    are within the specified range.\n",
    "    \"\"\"\n",
    "    valid_length_entries = set()\n",
    "    for i in range(len(dataset_df)):\n",
    "        row_dict = dataset_df.iloc[i].to_dict()\n",
    "\n",
    "        asmb_lengths_path = row_dict[\"asmb_lengths_path\"]\n",
    "\n",
    "        # Read the assembly lengths from the file.\n",
    "        asmb_lengths = np.load(asmb_lengths_path, allow_pickle = True).item()\n",
    "\n",
    "        for assembly_id in asmb_lengths:\n",
    "            (macromolecule_L, protein_L, dna_L, rna_L) = asmb_lengths[assembly_id]\n",
    "\n",
    "            if macromolecule_L <= max_length and macromolecule_L >= min_length:\n",
    "                valid_length_entries.add(row_dict[\"id\"])\n",
    "                break\n",
    "        \n",
    "    # Subset the dataframe to only include rows where the assembly lengths\n",
    "    # are valid.\n",
    "    dataset_df_subset = dataset_df[\n",
    "        dataset_df[\"id\"].apply(\n",
    "            lambda id: id in valid_length_entries\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    return dataset_df_subset\n",
    "\n",
    "def get_rna_monomer_subset(dataset_df):\n",
    "    \"\"\"\n",
    "    Get a subset of the dataset dataframe where the entry is a RNA monomer.\n",
    "    \"\"\"\n",
    "    rna_monomer_entries = set()\n",
    "    for i in range(len(dataset_df)):\n",
    "        row_dict = dataset_df.iloc[i].to_dict()\n",
    "\n",
    "        # Get the chain types.\n",
    "        sequences_path = row_dict[\"sequences_path\"]\n",
    "\n",
    "        sequences_df = pd.read_csv(sequences_path)\n",
    "\n",
    "        protein_chains = 0\n",
    "        dna_chains = 0\n",
    "        rna_chains = 0\n",
    "        dna_rna_hybrid_chains = 0\n",
    "        for chain_type in sequences_df[\"chain_type\"]:\n",
    "            if chain_type == \"polypeptide(L)\":\n",
    "                protein_chains += 1\n",
    "            elif chain_type == \"polydeoxyribonucleotide\":\n",
    "                dna_chains += 1\n",
    "            elif chain_type == \"polyribonucleotide\":\n",
    "                rna_chains += 1\n",
    "            elif chain_type == \"polydeoxyribonucleotide/polyribonucleotide hybrid\":\n",
    "                dna_rna_hybrid_chains += 1\n",
    "\n",
    "        if rna_chains == 1 and dna_chains == 0 and protein_chains == 0 and dna_rna_hybrid_chains == 0:\n",
    "            rna_monomer_entries.add(row_dict[\"id\"])\n",
    "        \n",
    "    dataset_df_subset = dataset_df[\n",
    "        dataset_df[\"id\"].apply(\n",
    "            lambda id: id in rna_monomer_entries\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    return dataset_df_subset\n",
    "\n",
    "def get_ppm_subset(dataset_df):\n",
    "    \"\"\"\n",
    "    Get a subset of the dataset dataframe where the PPM paths are not empty.\n",
    "    \"\"\"\n",
    "    # Subset the dataframe to only include rows where the PPM paths are not empty.\n",
    "    dataset_df_subset = dataset_df[\n",
    "        dataset_df[\"ppm_paths\"].apply(\n",
    "            lambda ppm_paths_str: len(ast.literal_eval(ppm_paths_str)) > 0\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    return dataset_df_subset\n",
    "\n",
    "\n",
    "def get_entries_in_same_clusters_as_specified_entries(\n",
    "        dataset_df,\n",
    "        entry_ids,\n",
    "        cluster_ids_column_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a subset of the dataset dataframe where the clusters fall into the\n",
    "    same clusters as the specified entries.\n",
    "    \"\"\"\n",
    "    entry_cluster_ids = set()\n",
    "    for entry_id in entry_ids:\n",
    "        row_dict = dataset_df[dataset_df[\"id\"] == entry_id].iloc[0].to_dict()\n",
    "        cluster_ids = ast.literal_eval(row_dict[cluster_ids_column_name])\n",
    "        entry_cluster_ids.update(cluster_ids)\n",
    "\n",
    "    dataset_df_subset = dataset_df[\n",
    "        dataset_df[cluster_ids_column_name].apply(\n",
    "            lambda cluster_ids_str: all(\n",
    "                [cluster_id in entry_cluster_ids for cluster_id in ast.literal_eval(cluster_ids_str)]\n",
    "            )\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    return dataset_df_subset\n",
    "\n",
    "def get_polymer_type_statistics(dataset_df):\n",
    "    \"\"\"\n",
    "    Print the number of different types of entries in the dataset.\n",
    "    The types of entries are:\n",
    "    - DNA\n",
    "    - RNA\n",
    "    - DNA/RNA hybrid\n",
    "    - Protein/DNA\n",
    "    - Protein/RNA\n",
    "    - Protein/DNA/RNA hybrid\n",
    "    \"\"\"\n",
    "    dna_entries = set()\n",
    "    rna_entries = set()\n",
    "    dna_rna_hybrid_entries = set()\n",
    "    protein_dna_entries = set()\n",
    "    protein_rna_entries = set()\n",
    "    protein_dna_rna_hybrid_entries = set()\n",
    "    for i in range(len(dataset_df)):\n",
    "        row_dict = dataset_df.iloc[i].to_dict()\n",
    "\n",
    "        nucleic_acid_chain_cluster_ids_chain_types = ast.literal_eval(\n",
    "            row_dict[\"nucleic_acid_chain_cluster_ids_chain_types\"]\n",
    "        )\n",
    "        protein_chain_cluster_ids_chain_types = ast.literal_eval(\n",
    "            row_dict[\"protein_chain_cluster_ids_chain_types\"]\n",
    "        )\n",
    "\n",
    "        has_protein = len(protein_chain_cluster_ids_chain_types) > 0\n",
    "        has_dna = \"polydeoxyribonucleotide\" in nucleic_acid_chain_cluster_ids_chain_types\n",
    "        has_rna = \"polyribonucleotide\" in nucleic_acid_chain_cluster_ids_chain_types\n",
    "        has_dna_rna_hybrid = \"polydeoxyribonucleotide/polyribonucleotide hybrid\" in nucleic_acid_chain_cluster_ids_chain_types\n",
    "\n",
    "        if has_protein and has_dna and not has_rna and not has_dna_rna_hybrid:\n",
    "            protein_dna_entries.add(row_dict[\"id\"])\n",
    "        elif has_protein and has_rna and not has_dna and not has_dna_rna_hybrid:\n",
    "            protein_rna_entries.add(row_dict[\"id\"])\n",
    "        elif has_protein and has_dna_rna_hybrid and not has_dna and not has_rna:\n",
    "            protein_dna_rna_hybrid_entries.add(row_dict[\"id\"])\n",
    "        elif has_dna and not has_protein and not has_rna and not has_dna_rna_hybrid:\n",
    "            dna_entries.add(row_dict[\"id\"])\n",
    "        elif has_rna and not has_protein and not has_dna and not has_dna_rna_hybrid:\n",
    "            rna_entries.add(row_dict[\"id\"])\n",
    "        elif has_dna_rna_hybrid and not has_protein and not has_dna and not has_rna:\n",
    "            dna_rna_hybrid_entries.add(row_dict[\"id\"])\n",
    "\n",
    "    print(\"Number of total entries:\", len(dataset_df))\n",
    "    print(\"Number of DNA entries:\", len(dna_entries))\n",
    "    print(\"Number of RNA entries:\", len(rna_entries))\n",
    "    print(\"Number of DNA/RNA hybrid entries:\", len(dna_rna_hybrid_entries))\n",
    "    print(\"Number of protein/DNA entries:\", len(protein_dna_entries))\n",
    "    print(\"Number of protein/RNA entries:\", len(protein_rna_entries))\n",
    "    print(\"Number of protein/DNA/RNA hybrid entries:\", len(protein_dna_rna_hybrid_entries))\n",
    "\n",
    "def get_ppm_statistics(dataset_df):\n",
    "    \"\"\"\n",
    "    Print the number of different types of entries in the dataset.\n",
    "    The types of entries are:\n",
    "    - PPM\n",
    "    - PPM from crystal\n",
    "    - PPM from distillation\n",
    "    \"\"\"\n",
    "    # Count the number of different types of entries.\n",
    "    ppm_entries = set()\n",
    "    ppm_from_crystal_entries = set()\n",
    "    ppm_from_distillation_entries = set()\n",
    "    for i in range(len(dataset_df)):\n",
    "        row_dict = dataset_df.iloc[i].to_dict()\n",
    "\n",
    "        ppm_paths = ast.literal_eval(\n",
    "            row_dict[\"ppm_paths\"]\n",
    "        )\n",
    "\n",
    "        has_ppm = len(ppm_paths) > 0\n",
    "        ppm_from_crystal = row_dict[\"dataset_name\"] == \"rcsb_cif_na\"\n",
    "        ppm_from_distillation = (row_dict[\"dataset_name\"] == \"rf2na_distillation_cis_bp\") or (row_dict[\"dataset_name\"] == \"rf2na_distillation_transfac\")\n",
    "\n",
    "        if has_ppm:\n",
    "            ppm_entries.add(row_dict[\"id\"])\n",
    "            if ppm_from_crystal:\n",
    "                ppm_from_crystal_entries.add(row_dict[\"id\"])\n",
    "            elif ppm_from_distillation:\n",
    "                ppm_from_distillation_entries.add(row_dict[\"id\"])\n",
    "\n",
    "    print(\"Number of total entries:\", len(dataset_df))\n",
    "    print(\"Number of PPM entries:\", len(ppm_entries))\n",
    "    print(\"Number of PPM from crystal entries:\", len(ppm_from_crystal_entries))\n",
    "    print(\"Number of PPM from distillation entries:\", len(ppm_from_distillation_entries))\n",
    "\n",
    "def load_rna_solo_paths(rfam_pdb_directory, bgsu_pdb_directory):\n",
    "    \"\"\"\n",
    "    Load the RNA-Solo paths from the BGSU and RFAM directories. Load the \n",
    "    BGSU paths first, then the BGSU paths.\n",
    "    \"\"\"\n",
    "    rfam_pattern = os.path.join(\n",
    "        rfam_pdb_directory,\n",
    "        \"*\",\n",
    "        \"*.pdb\"\n",
    "    )\n",
    "    bgsu_pattern = os.path.join(\n",
    "        bgsu_pdb_directory,\n",
    "        \"*\",\n",
    "        \"*.pdb\"\n",
    "    )\n",
    "\n",
    "    pdb_id_to_rfam_paths = dict()\n",
    "    for pdb_path in glob.glob(rfam_pattern):\n",
    "        basename = os.path.basename(pdb_path)\n",
    "        if basename.startswith(\"PDB_0000\"):\n",
    "            pdb_id = basename.split(\"PDB_0000\")[1].split(\"_\")[0].lower()\n",
    "        else:\n",
    "            pdb_id = basename.split(\"_\")[0].lower()\n",
    "        \n",
    "        if pdb_id not in pdb_id_to_rfam_paths:\n",
    "            pdb_id_to_rfam_paths[pdb_id] = []\n",
    "        pdb_id_to_rfam_paths[pdb_id].append(pdb_path)\n",
    "\n",
    "    pdb_id_to_bgsu_paths = dict()\n",
    "    for pdb_path in glob.glob(bgsu_pattern):\n",
    "        basename = os.path.basename(pdb_path)\n",
    "        if basename.startswith(\"PDB_0000\"):\n",
    "            pdb_id = basename.split(\"PDB_0000\")[1].split(\"_\")[0].lower()\n",
    "        else:\n",
    "            pdb_id = basename.split(\"_\")[0].lower()\n",
    "        \n",
    "        if pdb_id not in pdb_id_to_bgsu_paths:\n",
    "            pdb_id_to_bgsu_paths[pdb_id] = []\n",
    "        \n",
    "        pdb_id_to_bgsu_paths[pdb_id].append(pdb_path)\n",
    "    \n",
    "    pdb_id_to_rna_solo_paths = dict()\n",
    "    for pdb_id in set(pdb_id_to_rfam_paths.keys()).union(\n",
    "        set(pdb_id_to_bgsu_paths.keys())\n",
    "    ):\n",
    "        pdb_id_to_rna_solo_paths[pdb_id] = []\n",
    "\n",
    "        # For the sake of the pseudoknot set, flip the order of the\n",
    "        # RFAM and BGSU paths for these two PDB IDs.\n",
    "        # This is due to issues with the RFAM pdbs for these two entries.\n",
    "        if pdb_id == \"1vc5\" or pdb_id == \"4znp\":\n",
    "            if pdb_id in pdb_id_to_bgsu_paths:\n",
    "                pdb_id_to_rna_solo_paths[pdb_id].extend(pdb_id_to_bgsu_paths[pdb_id])\n",
    "            if pdb_id in pdb_id_to_rfam_paths:\n",
    "                pdb_id_to_rna_solo_paths[pdb_id].extend(pdb_id_to_rfam_paths[pdb_id])\n",
    "        else:\n",
    "            if pdb_id in pdb_id_to_rfam_paths:\n",
    "                pdb_id_to_rna_solo_paths[pdb_id].extend(pdb_id_to_rfam_paths[pdb_id])\n",
    "            if pdb_id in pdb_id_to_bgsu_paths:\n",
    "                pdb_id_to_rna_solo_paths[pdb_id].extend(pdb_id_to_bgsu_paths[pdb_id])\n",
    "    \n",
    "    return pdb_id_to_rna_solo_paths\n",
    "\n",
    "def convert_cif_to_pdb(dataset_df, \n",
    "                       pdb_output_directory,  \n",
    "                       use_rna_solo = False,\n",
    "                       pdb_id_to_rna_solo_paths = None):\n",
    "    \"\"\"\n",
    "    Convert the CIF files in the dataset dataframe to PDB files.\n",
    "    \"\"\"\n",
    "    if use_rna_solo:\n",
    "        assert(pdb_id_to_rna_solo_paths is not None)\n",
    "    \n",
    "    os.makedirs(pdb_output_directory)\n",
    "    \n",
    "    dataset_df = dataset_df.copy()\n",
    "    successfully_converted_ids = set()\n",
    "    pdb_id_to_structure_path = dict()\n",
    "    pdb_id_to_original_structure_path = dict()\n",
    "    pdb_id_to_copied_structure_path = dict()\n",
    "    for i in range(len(dataset_df)):\n",
    "        row_dict = dataset_df.iloc[i].to_dict()\n",
    "\n",
    "        # Fetch the original structure path.\n",
    "        original_structure_path = row_dict[\"structure_path\"]\n",
    "        \n",
    "        # Compute the destination structure path.\n",
    "        destination_structure_path = os.path.join(\n",
    "            pdb_output_directory,\n",
    "            row_dict[\"id\"] + \".pdb\"\n",
    "        )\n",
    "\n",
    "        if use_rna_solo:\n",
    "            # Use the first RNA-Solo path if it exists.\n",
    "            rna_solo_paths = pdb_id_to_rna_solo_paths.get(row_dict[\"id\"], [])\n",
    "            if len(rna_solo_paths) == 0:\n",
    "                continue\n",
    "            structure_path_to_copy = rna_solo_paths[0]\n",
    "        else:\n",
    "            structure_path_to_copy = original_structure_path\n",
    "        \n",
    "        # Use a temp file to handle gzipped files.\n",
    "        try:\n",
    "            if structure_path_to_copy.endswith(\".gz\"):\n",
    "                structure_ext = os.path.splitext(structure_path_to_copy[:-3])[1]\n",
    "                \n",
    "                with (gzip.open(structure_path_to_copy, \"rb\") as f_in,\n",
    "                    tempfile.NamedTemporaryFile(suffix = structure_ext) as tmp):\n",
    "                    tmp.write(f_in.read())\n",
    "                    tmp.flush()\n",
    "                    atom_array = biotite.structure.io.load_structure(tmp.name)\n",
    "                    tmp.close()\n",
    "            else:\n",
    "                atom_array = biotite.structure.io.load_structure(structure_path_to_copy)\n",
    "            \n",
    "            biotite.structure.io.save_structure(destination_structure_path, atom_array)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Add the id to the set of successfully converted ids.\n",
    "        successfully_converted_ids.add(row_dict[\"id\"])\n",
    "\n",
    "        # Replace the destination structure path, original structure path,\n",
    "        # and copied structure path in the dataframe.\n",
    "        pdb_id_to_structure_path[row_dict[\"id\"]] = destination_structure_path\n",
    "        pdb_id_to_original_structure_path[row_dict[\"id\"]] = original_structure_path\n",
    "        pdb_id_to_copied_structure_path[row_dict[\"id\"]] = structure_path_to_copy\n",
    "    \n",
    "    # Create a new dataframe with the successfully converted ids.\n",
    "    dataset_subset_df = dataset_df[\n",
    "        dataset_df[\"id\"].apply(\n",
    "            lambda id: id in successfully_converted_ids\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    # Replace the structure path in the new dataframe with the destination\n",
    "    # structure path.\n",
    "    dataset_subset_df[\"structure_path\"] = dataset_subset_df[\"id\"].apply(\n",
    "        lambda id: pdb_id_to_structure_path[id]\n",
    "    )\n",
    "    dataset_subset_df[\"original_structure_path\"] = dataset_subset_df[\"id\"].apply(\n",
    "        lambda id: pdb_id_to_original_structure_path[id]\n",
    "    )\n",
    "    dataset_subset_df[\"copied_structure_path\"] = dataset_subset_df[\"id\"].apply(\n",
    "        lambda id: pdb_id_to_copied_structure_path[id]\n",
    "    )\n",
    "\n",
    "    return dataset_subset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the RNASolo Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id_to_rna_solo_paths = load_rna_solo_paths(\n",
    "    rfam_pdb_directory = \"/home/akubaney/projects/data/rfam_rnasolo_2025_04_07/pdb\",\n",
    "    bgsu_pdb_directory = \"/home/akubaney/projects/data/bgsu_rnasolo_2025_05_01/pdb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the PDB Output Directory and the CSV Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_output_directory = os.path.abspath(\"./evaluation_pdbs\")\n",
    "csv_output_directory = os.path.abspath(\"./evaluation_csvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pdb_output_directory):\n",
    "    shutil.rmtree(pdb_output_directory)\n",
    "os.makedirs(pdb_output_directory)\n",
    "\n",
    "if os.path.exists(csv_output_directory):\n",
    "    shutil.rmtree(csv_output_directory)\n",
    "os.makedirs(csv_output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_valid_csv_path = \"/home/akubaney/projects/na_mpnn/data/datasets/design_dataset_v2/valid.csv\"\n",
    "design_valid_cluster_ids_path = \"/home/akubaney/projects/na_mpnn/data/datasets/design_dataset_v2/valid_nucleic_acid_chain_cluster_ids.txt\"\n",
    "\n",
    "design_test_csv_path = \"/home/akubaney/projects/na_mpnn/data/datasets/design_dataset_v2/test.csv\"\n",
    "design_test_cluster_ids_path = \"/home/akubaney/projects/na_mpnn/data/datasets/design_dataset_v2/test_nucleic_acid_chain_cluster_ids.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_valid_pdbs_output_directory = os.path.join(pdb_output_directory, \"design_valid\")\n",
    "design_valid_csv_output_path = os.path.join(csv_output_directory, \"design_valid.csv\")\n",
    "\n",
    "design_valid_df = pd.read_csv(design_valid_csv_path)\n",
    "design_valid_cluster_ids = read_cluster_ids_text_file(design_valid_cluster_ids_path)\n",
    "print(\"Original valid dataset size:\", len(design_valid_df))\n",
    "\n",
    "design_valid_df = get_exclusive_cluster_subset(\n",
    "    design_valid_df, \n",
    "    \"nucleic_acid_chain_cluster_ids\", \n",
    "    design_valid_cluster_ids\n",
    ")\n",
    "print(\"Valid dataset size after exclusive cluster subset:\", len(design_valid_df))\n",
    "\n",
    "design_valid_df = get_length_subset(\n",
    "    design_valid_df,\n",
    "    max_length = 1000,\n",
    "    min_length = 20\n",
    ")\n",
    "print(\"Valid dataset size after length subset:\", len(design_valid_df))\n",
    "\n",
    "design_valid_df = convert_cif_to_pdb(\n",
    "    design_valid_df, \n",
    "    design_valid_pdbs_output_directory, \n",
    "    use_rna_solo = False,\n",
    "    pdb_id_to_rna_solo_paths = None\n",
    ")\n",
    "print(\"Valid dataset size after CIF to PDB conversion:\", len(design_valid_df))\n",
    "\n",
    "get_polymer_type_statistics(design_valid_df)\n",
    "\n",
    "design_valid_df.to_csv(design_valid_csv_output_path, index = False)\n",
    "design_valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_test_pdbs_output_directory = os.path.join(pdb_output_directory, \"design_test\")\n",
    "design_test_csv_output_path = os.path.join(csv_output_directory, \"design_test.csv\")\n",
    "\n",
    "design_test_df = pd.read_csv(design_test_csv_path)\n",
    "design_test_cluster_ids = read_cluster_ids_text_file(design_test_cluster_ids_path)\n",
    "print(\"Original test dataset size:\", len(design_test_df))\n",
    "\n",
    "design_test_df = get_exclusive_cluster_subset(\n",
    "    design_test_df, \n",
    "    \"nucleic_acid_chain_cluster_ids\", \n",
    "    design_test_cluster_ids\n",
    ")\n",
    "print(\"Test dataset size after exclusive cluster subset:\", len(design_test_df))\n",
    "\n",
    "design_test_df = get_length_subset(\n",
    "    design_test_df,\n",
    "    max_length = 1000,\n",
    "    min_length = 20\n",
    ")\n",
    "print(\"Test dataset size after length subset:\", len(design_test_df))\n",
    "\n",
    "design_test_df = convert_cif_to_pdb(\n",
    "    design_test_df, \n",
    "    design_test_pdbs_output_directory, \n",
    "    use_rna_solo = False,\n",
    "    pdb_id_to_rna_solo_paths = None\n",
    ")\n",
    "print(\"Test dataset size after CIF to PDB conversion:\", len(design_test_df))\n",
    "\n",
    "get_polymer_type_statistics(design_test_df)\n",
    "\n",
    "design_test_df.to_csv(design_test_csv_output_path, index = False)\n",
    "design_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA Monomer Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_rna_monomer_test_pdbs_output_directory = os.path.join(pdb_output_directory, \"design_rna_monomer_test\")\n",
    "design_rna_monomer_test_csv_output_path = os.path.join(csv_output_directory, \"design_rna_monomer_test.csv\")\n",
    "\n",
    "design_test_df = pd.read_csv(design_test_csv_path)\n",
    "design_test_cluster_ids = read_cluster_ids_text_file(design_test_cluster_ids_path)\n",
    "print(\"Original test dataset size:\", len(design_test_df))\n",
    "\n",
    "design_test_df = get_exclusive_cluster_subset(\n",
    "    design_test_df, \n",
    "    \"nucleic_acid_chain_cluster_ids\", \n",
    "    design_test_cluster_ids\n",
    ")\n",
    "print(\"Test dataset size after exclusive cluster subset:\", len(design_test_df))\n",
    "\n",
    "design_rna_monomer_test_df = get_rna_monomer_subset(design_test_df)\n",
    "print(\"Test dataset size after RNA monomer subset:\", len(design_rna_monomer_test_df))\n",
    "\n",
    "design_rna_monomer_test_df = get_length_subset(\n",
    "    design_rna_monomer_test_df,\n",
    "    max_length = 1000,\n",
    "    min_length = 20\n",
    ")\n",
    "print(\"Test dataset size after length subset:\", len(design_rna_monomer_test_df))\n",
    "\n",
    "design_rna_monomer_test_df = convert_cif_to_pdb(\n",
    "    design_rna_monomer_test_df, \n",
    "    design_rna_monomer_test_pdbs_output_directory, \n",
    "    use_rna_solo = True,\n",
    "    pdb_id_to_rna_solo_paths = pdb_id_to_rna_solo_paths\n",
    ")\n",
    "print(\"Test dataset size after CIF to PDB conversion:\", len(design_rna_monomer_test_df))\n",
    "\n",
    "get_polymer_type_statistics(design_rna_monomer_test_df)\n",
    "\n",
    "design_rna_monomer_test_df.to_csv(design_rna_monomer_test_csv_output_path, index = False)\n",
    "design_rna_monomer_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudoknot Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudoknot_pdb_ids = [\"7kd1\", \"3q3z\", \"4plx\", \"2m8k\", \"4oqu\", \"7kga\", \"1drz\", \"7qr4\", \"2miy\", \"4znp\"]\n",
    "\n",
    "design_pseudoknot_test_pdbs_output_directory = os.path.join(pdb_output_directory, \"design_pseudoknot_test\")\n",
    "design_pseudoknot_test_csv_output_path = os.path.join(csv_output_directory, \"design_pseudoknot_test.csv\")\n",
    "\n",
    "design_test_df = pd.read_csv(design_test_csv_path)\n",
    "design_test_cluster_ids = read_cluster_ids_text_file(design_test_cluster_ids_path)\n",
    "print(\"Original test dataset size:\", len(design_test_df))\n",
    "\n",
    "design_test_df = get_exclusive_cluster_subset(\n",
    "    design_test_df, \n",
    "    \"nucleic_acid_chain_cluster_ids\", \n",
    "    design_test_cluster_ids\n",
    ")\n",
    "print(\"Test dataset size after exclusive cluster subset:\", len(design_test_df))\n",
    "\n",
    "design_pseudoknot_test_df = get_entries_in_same_clusters_as_specified_entries(\n",
    "    design_test_df,\n",
    "    pseudoknot_pdb_ids,\n",
    "    \"nucleic_acid_chain_cluster_ids\"\n",
    ")\n",
    "print(\"Test dataset size after pseudoknot subset:\", len(design_pseudoknot_test_df))\n",
    "\n",
    "design_pseudoknot_test_df = get_length_subset(\n",
    "    design_pseudoknot_test_df,\n",
    "    max_length = 1000,\n",
    "    min_length = 20\n",
    ")\n",
    "print(\"Test dataset size after length subset:\", len(design_pseudoknot_test_df))\n",
    "\n",
    "design_pseudoknot_test_df = convert_cif_to_pdb(\n",
    "    design_pseudoknot_test_df, \n",
    "    design_pseudoknot_test_pdbs_output_directory, \n",
    "    use_rna_solo = True,\n",
    "    pdb_id_to_rna_solo_paths = pdb_id_to_rna_solo_paths\n",
    ")\n",
    "print(\"Test dataset size after CIF to PDB conversion:\", len(design_pseudoknot_test_df))\n",
    "\n",
    "get_polymer_type_statistics(design_pseudoknot_test_df)\n",
    "\n",
    "design_pseudoknot_test_df.to_csv(design_pseudoknot_test_csv_output_path, index = False)\n",
    "design_pseudoknot_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_valid_csv_path = \"/home/akubaney/projects/na_mpnn/data/datasets/specificity_dataset_v2/valid.csv\"\n",
    "specificity_valid_cluster_ids_path = \"/home/akubaney/projects/na_mpnn/data/datasets/specificity_dataset_v2/valid_protein_chain_cluster_ids.txt\"\n",
    "\n",
    "specificity_test_csv_path = \"/home/akubaney/projects/na_mpnn/data/datasets/specificity_dataset_v2/test.csv\"\n",
    "specificity_test_cluster_ids_path = \"/home/akubaney/projects/na_mpnn/data/datasets/specificity_dataset_v2/test_protein_chain_cluster_ids.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_valid_pdbs_output_directory = os.path.join(pdb_output_directory, \"specificity_valid\")\n",
    "specificity_valid_csv_output_path = os.path.join(csv_output_directory, \"specificity_valid.csv\")\n",
    "\n",
    "specificity_valid_df = pd.read_csv(specificity_valid_csv_path)\n",
    "specificity_valid_cluster_ids = read_cluster_ids_text_file(specificity_valid_cluster_ids_path)\n",
    "print(\"Original valid dataset size:\", len(specificity_valid_df))\n",
    "\n",
    "specificity_valid_df = get_exclusive_cluster_subset(\n",
    "    specificity_valid_df, \n",
    "    \"protein_chain_cluster_ids\", \n",
    "    specificity_valid_cluster_ids\n",
    ")\n",
    "print(\"Valid dataset size after exclusive cluster subset:\", len(specificity_valid_df))\n",
    "\n",
    "specificity_valid_df = get_ppm_subset(specificity_valid_df)\n",
    "print(\"Valid dataset size after PPM subset:\", len(specificity_valid_df))\n",
    "\n",
    "specificity_valid_df = get_length_subset(\n",
    "    specificity_valid_df,\n",
    "    max_length = 1000,\n",
    "    min_length = 20\n",
    ")\n",
    "print(\"Valid dataset size after length subset:\", len(specificity_valid_df))\n",
    "\n",
    "specificity_valid_df = convert_cif_to_pdb(\n",
    "    specificity_valid_df, \n",
    "    specificity_valid_pdbs_output_directory, \n",
    "    use_rna_solo = False,\n",
    "    pdb_id_to_rna_solo_paths = None\n",
    ")\n",
    "print(\"Valid dataset size after CIF to PDB conversion:\", len(specificity_valid_df))\n",
    "\n",
    "get_ppm_statistics(specificity_valid_df)\n",
    "\n",
    "specificity_valid_df.to_csv(specificity_valid_csv_output_path, index = False)\n",
    "specificity_valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_test_pdbs_output_directory = os.path.join(pdb_output_directory, \"specificity_test\")\n",
    "specificity_test_csv_output_path = os.path.join(csv_output_directory, \"specificity_test.csv\")\n",
    "\n",
    "specificity_test_df = pd.read_csv(specificity_test_csv_path)\n",
    "specificity_test_cluster_ids = read_cluster_ids_text_file(specificity_test_cluster_ids_path)\n",
    "print(\"Original test dataset size:\", len(specificity_test_df))\n",
    "\n",
    "specificity_test_df = get_exclusive_cluster_subset(\n",
    "    specificity_test_df, \n",
    "    \"protein_chain_cluster_ids\", \n",
    "    specificity_test_cluster_ids\n",
    ")\n",
    "print(\"Test dataset size after exclusive cluster subset:\", len(specificity_test_df))\n",
    "\n",
    "specificity_test_df = get_ppm_subset(specificity_test_df)\n",
    "print(\"Test dataset size after PPM subset:\", len(specificity_test_df))\n",
    "\n",
    "specificity_test_df = get_length_subset(\n",
    "    specificity_test_df,\n",
    "    max_length = 1000,\n",
    "    min_length = 20\n",
    ")\n",
    "print(\"Test dataset size after length subset:\", len(specificity_test_df))\n",
    "\n",
    "specificity_test_df = convert_cif_to_pdb(\n",
    "    specificity_test_df, \n",
    "    specificity_test_pdbs_output_directory, \n",
    "    use_rna_solo = False,\n",
    "    pdb_id_to_rna_solo_paths = None\n",
    ")\n",
    "print(\"Test dataset size after CIF to PDB conversion:\", len(specificity_test_df))\n",
    "\n",
    "get_ppm_statistics(specificity_test_df)\n",
    "\n",
    "specificity_test_df.to_csv(specificity_test_csv_output_path, index = False)\n",
    "specificity_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
