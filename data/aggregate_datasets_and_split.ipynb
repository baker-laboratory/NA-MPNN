{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final Datasets for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the datasets.\n",
    "all_datasets_directory = \"./datasets\"\n",
    "\n",
    "# Datasets to load for creating the final datasets.\n",
    "datasets_to_load = [\"rcsb_cif_na\", \"rf2na_distillation_cis_bp\", \"rf2na_distillation_transfac\"]\n",
    "\n",
    "# Path to protein chain clustering output.\n",
    "protein_chain_clustering_path = \"./clustering/all_protein_sequences/all_protein_sequences_clusters.csv\"\n",
    "\n",
    "# Path to nucleic acid clustering output.\n",
    "nucleic_acid_chain_clustering_path = \"./clustering/all_nucleic_acid_sequences/all_nucleic_acid_sequences_clusters.csv\"\n",
    "\n",
    "# Path to protein family labeling output.\n",
    "protein_family_labeling_path = \"./protein_family_labeling/all_protein_family_labels.csv\"\n",
    "\n",
    "# Output directory for the aggregate of all datasets.\n",
    "all_datasets_output_directory = os.path.join(all_datasets_directory, \"all_datasets\")\n",
    "all_datasets_output_path = os.path.join(all_datasets_output_directory, \"all_datasets.csv\")\n",
    "\n",
    "# Columns with list typing.\n",
    "list_columns = [\n",
    "    \"ppm_paths\", \n",
    "    \"protein_chain_cluster_ids\", \n",
    "    \"protein_chain_cluster_ids_chain_types\", \n",
    "    \"nucleic_acid_chain_cluster_ids\", \n",
    "    \"nucleic_acid_chain_cluster_ids_chain_types\", \n",
    "    \"pfam_ids\", \n",
    "    \"pfam_descriptions\", \n",
    "    \"interpro_ids\", \n",
    "    \"interpro_descriptions\"\n",
    "]\n",
    "\n",
    "# Output directory for the design dataset.\n",
    "design_dataset_output_directory = os.path.join(all_datasets_directory, \"design_dataset_v2\")\n",
    "specificity_dataset_output_directory = os.path.join(all_datasets_directory, \"specificity_dataset_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chain_cluster_degrees(data_df, chain_cluster_ids_column_name):\n",
    "    # Compute the degree of the chain clusters.\n",
    "    chain_cluster_id_to_degree = {}\n",
    "    for chain_cluster_ids in data_df[chain_cluster_ids_column_name]:\n",
    "        for chain_cluster_id in chain_cluster_ids:\n",
    "            chain_cluster_id_to_degree[chain_cluster_id] = chain_cluster_id_to_degree.get(chain_cluster_id, 0) + 1\n",
    "    \n",
    "    # Add a degree column to the data frame.\n",
    "    chain_cluster_degrees_column_name = chain_cluster_ids_column_name.replace(\"ids\", \"degrees\")\n",
    "    data_df[chain_cluster_degrees_column_name] = \\\n",
    "        data_df[chain_cluster_ids_column_name].apply(lambda chain_cluster_ids: [chain_cluster_id_to_degree[chain_cluster_id] for chain_cluster_id in chain_cluster_ids])\n",
    "\n",
    "    return chain_cluster_id_to_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(path):\n",
    "    with open(path, mode = \"rt\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def write_text_file(path, content):\n",
    "    with open(path, mode = \"wt\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_seed(path):\n",
    "    return int(read_text_file(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_test_clusters(chain_cluster_to_degree,\n",
    "                                    valid_fraction,\n",
    "                                    test_fraction,\n",
    "                                    max_valid_test_cluster_degree,\n",
    "                                    extra_test_cluster_ids,\n",
    "                                    seed):\n",
    "    # Create the rng.\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    all_cluster_ids = list(chain_cluster_to_degree.keys())\n",
    "    # Choose a random sub-sample of chain clusters for validation/test.\n",
    "    if max_valid_test_cluster_degree is None:\n",
    "        cluster_ids_for_valid_test = all_cluster_ids\n",
    "    else:\n",
    "        cluster_ids_for_valid_test = [cluster_id for cluster_id in all_cluster_ids if chain_cluster_to_degree[cluster_id] <= max_valid_test_cluster_degree]\n",
    "    \n",
    "    # Remove the extra test cluster ids from the valid/test cluster ids.\n",
    "    if extra_test_cluster_ids is not None:\n",
    "        cluster_ids_for_valid_test = list(set(cluster_ids_for_valid_test) - set(extra_test_cluster_ids))\n",
    "\n",
    "    # Ensure there are enough clusters for the valid and test sets with the\n",
    "    # appropriate degree.\n",
    "    assert((len(cluster_ids_for_valid_test) / len(all_cluster_ids)) >= (test_fraction + valid_fraction))\n",
    "\n",
    "    # Choose the test and valid cluster ids.\n",
    "    test_cluster_ids = rng.choice(list(cluster_ids_for_valid_test), \n",
    "                                  size = int(test_fraction * len(all_cluster_ids)), \n",
    "                                  replace = False)\n",
    "    valid_cluster_ids = rng.choice(list(set(cluster_ids_for_valid_test) - set(test_cluster_ids)), \n",
    "                                   size = int(valid_fraction * len(all_cluster_ids)), \n",
    "                                   replace = False)\n",
    "\n",
    "    # Add the extra test cluster ids to the test set.\n",
    "    if extra_test_cluster_ids is not None:\n",
    "        test_cluster_ids = list(set(test_cluster_ids).union(set(extra_test_cluster_ids)))\n",
    "    \n",
    "    # The train clusters are the rest of the clusters.\n",
    "    train_cluster_ids = list(set(all_cluster_ids) - set(valid_cluster_ids) - set(test_cluster_ids))\n",
    "\n",
    "    # Check that the train, validation, and test clusters are disjoint.\n",
    "    assert(len(set(train_cluster_ids).intersection(set(valid_cluster_ids))) == 0)\n",
    "    assert(len(set(train_cluster_ids).intersection(set(test_cluster_ids))) == 0)\n",
    "    assert(len(set(valid_cluster_ids).intersection(set(test_cluster_ids))) == 0)\n",
    "\n",
    "    # Assert that nothing is left out from all.\n",
    "    assert(len(set(train_cluster_ids).union(set(valid_cluster_ids)).union(set(test_cluster_ids))) == len(all_cluster_ids))\n",
    "\n",
    "    print(f\"clusters: {len(all_cluster_ids)}\")\n",
    "    print(f\"train clusters: {len(train_cluster_ids)}\")\n",
    "    print(f\"validation clusters: {len(valid_cluster_ids)}\")\n",
    "    print(f\"test clusters: {len(test_cluster_ids)}\")\n",
    "    print()\n",
    "\n",
    "    return train_cluster_ids, valid_cluster_ids, test_cluster_ids\n",
    "\n",
    "def split_train_valid_test_entries(data_df, \n",
    "                                   chain_cluster_ids_column_name,\n",
    "                                   train_cluster_ids,\n",
    "                                   valid_cluster_ids,\n",
    "                                   test_cluster_ids):\n",
    "    # Assert all entry ids in the dataset are unique.\n",
    "    assert(len(set(data_df[\"id\"])) == len(data_df))\n",
    "\n",
    "    # Get the dataset entries for each set.\n",
    "    test_entry_ids = []\n",
    "    valid_entry_ids = []\n",
    "    train_entry_ids = []\n",
    "    test_cluster_ids_set = set(test_cluster_ids)\n",
    "    valid_cluster_ids_set = set(valid_cluster_ids)\n",
    "    for id, chain_cluster_ids in zip(data_df[\"id\"], data_df[chain_cluster_ids_column_name]):\n",
    "        if len(set(chain_cluster_ids).intersection(test_cluster_ids_set)) > 0:\n",
    "            test_entry_ids.append(id)\n",
    "        elif len(set(chain_cluster_ids).intersection(valid_cluster_ids_set)) > 0:\n",
    "            valid_entry_ids.append(id)\n",
    "        else:\n",
    "            train_entry_ids.append(id)\n",
    "    \n",
    "    # Check that the train, validation, and test entries are disjoint.\n",
    "    assert(len(set(train_entry_ids).intersection(set(valid_entry_ids))) == 0)\n",
    "    assert(len(set(train_entry_ids).intersection(set(test_entry_ids))) == 0)\n",
    "    assert(len(set(valid_entry_ids).intersection(set(test_entry_ids))) == 0)\n",
    "\n",
    "    # Assert that nothing is left out from all.\n",
    "    assert(len(set(train_entry_ids).union(set(valid_entry_ids)).union(set(test_entry_ids))) == len(data_df))\n",
    "\n",
    "    # Split the data into train, validation, and test sets.\n",
    "    train_data_df = data_df[data_df[\"id\"].isin(train_entry_ids)]\n",
    "    valid_data_df = data_df[data_df[\"id\"].isin(valid_entry_ids)]\n",
    "    test_data_df = data_df[data_df[\"id\"].isin(test_entry_ids)]\n",
    "\n",
    "    # Assert that the train and valid dataframes don't contain any chains from\n",
    "    # the test set, and that the train dataframe doesn't contain any chains from\n",
    "    # the validation set.\n",
    "    for chain_cluster_ids in train_data_df[chain_cluster_ids_column_name]:\n",
    "        assert(len(set(chain_cluster_ids).intersection(set(test_cluster_ids))) == 0)\n",
    "        assert(len(set(chain_cluster_ids).intersection(set(valid_cluster_ids))) == 0)\n",
    "    for chain_cluster_ids in valid_data_df[chain_cluster_ids_column_name]:\n",
    "        assert(len(set(chain_cluster_ids).intersection(set(test_cluster_ids))) == 0)\n",
    "\n",
    "    print(f\"entries: {len(data_df)}\")\n",
    "    print(f\"train entries: {len(train_data_df)}\")\n",
    "    print(f\"validation entries: {len(valid_data_df)}\")\n",
    "    print(f\"test entries: {len(test_data_df)}\")\n",
    "    print()\n",
    "\n",
    "    return train_data_df, valid_data_df, test_data_df\n",
    "\n",
    "def evaluate_train_valid_test_split(split_dfs): \n",
    "    for split_name, split_df in split_dfs.items():\n",
    "        # Count number of DNA/RNA/hybrid entries with and without protein in \n",
    "        # dataset.\n",
    "        dna_entries = 0\n",
    "        rna_entries = 0\n",
    "        dna_rna_entries = 0\n",
    "        dna_entries_with_protein = 0\n",
    "        rna_entries_with_protein = 0\n",
    "        dna_rna_entries_with_protein = 0\n",
    "        # Count number of entries with PPMs, from crystal and distillation.\n",
    "        entries_with_ppm = 0\n",
    "        entries_with_ppm_from_crystal = 0\n",
    "        entries_with_pmm_from_distill = 0\n",
    "        # Record the pfam id and pfam description entry counts, only counting\n",
    "        # entries with ppms.\n",
    "        pfam_id_with_ppm_counts = {}\n",
    "        pfam_id_with_ppm_counts_from_crystal = {}\n",
    "        pfam_id_with_ppm_counts_from_distill = {}\n",
    "        pfam_description_with_ppm_counts = {}\n",
    "        pfam_description_with_ppm_counts_from_crystal = {}\n",
    "        pfam_description_with_ppm_counts_from_distill = {}\n",
    "        for (protein_chain_cluster_ids, \n",
    "             nucleic_acid_chain_cluster_ids_chain_types,\n",
    "             ppm_paths,\n",
    "             dataset_name,\n",
    "             pfam_ids,\n",
    "             pfam_descriptions) in zip(\n",
    "            split_df[\"protein_chain_cluster_ids\"], \n",
    "            split_df[\"nucleic_acid_chain_cluster_ids_chain_types\"],\n",
    "            split_df[\"ppm_paths\"],\n",
    "            split_df[\"dataset_name\"],\n",
    "            split_df[\"pfam_ids\"],\n",
    "            split_df[\"pfam_descriptions\"]\n",
    "        ):\n",
    "            # Count the number of DNA/RNA/hybrid entries with and without \n",
    "            # protein in the complex.\n",
    "            protein_in_complex = (len(protein_chain_cluster_ids) > 0)\n",
    "            dna_in_complex = (nucleic_acid_chain_cluster_ids_chain_types.count(\"polydeoxyribonucleotide\") > 0)\n",
    "            rna_in_complex = (nucleic_acid_chain_cluster_ids_chain_types.count(\"polyribonucleotide\") > 0)\n",
    "            dna_rna_hybrid_in_complex = (nucleic_acid_chain_cluster_ids_chain_types.count(\"polydeoxyribonucleotide/polyribonucleotide hybrid\") > 0)\n",
    "            if dna_in_complex:\n",
    "                if protein_in_complex:\n",
    "                    dna_entries_with_protein += 1\n",
    "                else:\n",
    "                    dna_entries += 1\n",
    "            if rna_in_complex:\n",
    "                if protein_in_complex:\n",
    "                    rna_entries_with_protein += 1\n",
    "                else:\n",
    "                    rna_entries += 1\n",
    "            if dna_rna_hybrid_in_complex:\n",
    "                if protein_in_complex:\n",
    "                    dna_rna_entries_with_protein += 1\n",
    "                else:\n",
    "                    dna_rna_entries += 1\n",
    "            \n",
    "            # Count the number of entries with PPMs, as well as record pfam\n",
    "            # id and description counts for entries with PPMs.\n",
    "            if len(ppm_paths) > 0:\n",
    "                entries_with_ppm += 1\n",
    "                if dataset_name == \"rcsb_cif_na\":\n",
    "                    entries_with_ppm_from_crystal += 1\n",
    "                elif dataset_name == \"rf2na_distillation_cis_bp\" or dataset_name == \"rf2na_distillation_transfac\":\n",
    "                    entries_with_pmm_from_distill += 1\n",
    "\n",
    "                # Only record each pfam id and description once per entry,\n",
    "                # because there may not be a one-to-one correspondence between\n",
    "                # chains and PPMs.\n",
    "                for pfam_id in set(pfam_ids):\n",
    "                    pfam_id_with_ppm_counts[pfam_id] = pfam_id_with_ppm_counts.get(pfam_id, 0) + 1\n",
    "                    if dataset_name == \"rcsb_cif_na\":\n",
    "                        pfam_id_with_ppm_counts_from_crystal[pfam_id] = pfam_id_with_ppm_counts_from_crystal.get(pfam_id, 0) + 1\n",
    "                    elif dataset_name == \"rf2na_distillation_cis_bp\" or dataset_name == \"rf2na_distillation_transfac\":\n",
    "                        pfam_id_with_ppm_counts_from_distill[pfam_id] = pfam_id_with_ppm_counts_from_distill.get(pfam_id, 0) + 1\n",
    "\n",
    "                for pfam_description in set(pfam_descriptions):\n",
    "                    pfam_description_with_ppm_counts[pfam_description] = pfam_description_with_ppm_counts.get(pfam_description, 0) + 1\n",
    "                    if dataset_name == \"rcsb_cif_na\":\n",
    "                        pfam_description_with_ppm_counts_from_crystal[pfam_description] = pfam_description_with_ppm_counts_from_crystal.get(pfam_description, 0) + 1\n",
    "                    elif dataset_name == \"rf2na_distillation_cis_bp\" or dataset_name == \"rf2na_distillation_transfac\":\n",
    "                        pfam_description_with_ppm_counts_from_distill[pfam_description] = pfam_description_with_ppm_counts_from_distill.get(pfam_description, 0) + 1\n",
    "\n",
    "        print(f\"{split_name}\")\n",
    "        print(f\"\\tDNA entries: {dna_entries}\")\n",
    "        print(f\"\\tRNA entries: {rna_entries}\")\n",
    "        print(f\"\\tDNA/RNA hybrid entries: {dna_rna_entries}\")\n",
    "        print(f\"\\tDNA entries with protein in the complex: {dna_entries_with_protein}\")\n",
    "        print(f\"\\tRNA entries with protein in the complex: {rna_entries_with_protein}\")\n",
    "        print(f\"\\tDNA/RNA hybrid entries with protein in the complex: {dna_rna_entries_with_protein}\")\n",
    "        print(f\"\\tEntries with PPMs: {entries_with_ppm}\")\n",
    "        print(f\"\\tEntries with PPMs from crystal: {entries_with_ppm_from_crystal}\")\n",
    "        print(f\"\\tEntries with PPMs from distillation: {entries_with_pmm_from_distill}\")\n",
    "        print(f\"\\tPFAM id counts for entries with PPMs: {pfam_id_with_ppm_counts}\")\n",
    "        print(f\"\\tPFAM id counts for entries with PPMs from crystal: {pfam_id_with_ppm_counts_from_crystal}\")\n",
    "        print(f\"\\tPFAM id counts for entries with PPMs from distillation: {pfam_id_with_ppm_counts_from_distill}\")\n",
    "        print(f\"\\tPFAM description counts for entries with PPMs: {pfam_description_with_ppm_counts}\")\n",
    "        print(f\"\\tPFAM description counts for entries with PPMs from crystal: {pfam_description_with_ppm_counts_from_crystal}\")\n",
    "        print(f\"\\tPFAM description counts for entries with PPMs from distillation: {pfam_description_with_ppm_counts_from_distill}\")\n",
    "\n",
    "def save_train_valid_test_split(output_directory, \n",
    "                                chain_cluster_ids_column_name, \n",
    "                                data_df, \n",
    "                                split_dfs,\n",
    "                                split_cluster_ids,\n",
    "                                seed):\n",
    "    # Replace the output directory.\n",
    "    if os.path.exists(output_directory):\n",
    "        shutil.rmtree(output_directory)\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "    # Paths for the output dataframes.\n",
    "    all_df_path = os.path.join(output_directory, \"all.csv\")\n",
    "    train_df_path = os.path.join(output_directory, \"train.csv\")\n",
    "    valid_df_path = os.path.join(output_directory, \"valid.csv\")\n",
    "    test_df_path = os.path.join(output_directory, \"test.csv\")\n",
    "    \n",
    "    # Save the dataframes.\n",
    "    data_df.to_csv(all_df_path, index = False)\n",
    "    split_dfs[\"train\"].to_csv(train_df_path, index = False)\n",
    "    split_dfs[\"valid\"].to_csv(valid_df_path, index = False)\n",
    "    split_dfs[\"test\"].to_csv(test_df_path, index = False)\n",
    "\n",
    "    # Paths for the output cluster ids.\n",
    "    train_cluster_ids_path = os.path.join(output_directory, f\"train_{chain_cluster_ids_column_name}.txt\")\n",
    "    valid_cluster_ids_path = os.path.join(output_directory, f\"valid_{chain_cluster_ids_column_name}.txt\")\n",
    "    test_cluster_ids_path = os.path.join(output_directory, f\"test_{chain_cluster_ids_column_name}.txt\")\n",
    "\n",
    "    # Save the cluster ids.\n",
    "    write_text_file(train_cluster_ids_path, \"\\n\".join(map(str, split_cluster_ids[\"train\"])))\n",
    "    write_text_file(valid_cluster_ids_path, \"\\n\".join(map(str, split_cluster_ids[\"valid\"])))\n",
    "    write_text_file(test_cluster_ids_path, \"\\n\".join(map(str, split_cluster_ids[\"test\"])))\n",
    "\n",
    "    # Path for the seed.\n",
    "    seed_path = os.path.join(output_directory, \"seed.txt\")\n",
    "\n",
    "    # Save the seed.\n",
    "    write_text_file(seed_path, str(seed))\n",
    "\n",
    "\n",
    "def train_valid_test_split(data_df, \n",
    "                           chain_cluster_to_degree, \n",
    "                           chain_cluster_ids_column_name,\n",
    "                           output_directory,\n",
    "                           valid_fraction = None, \n",
    "                           test_fraction = None,\n",
    "                           max_valid_test_cluster_degree = None,\n",
    "                           extra_test_cluster_ids = None,\n",
    "                           seed = None):\n",
    "    \"\"\"\n",
    "    Split the data_df (grouped by entries) into train, validation, and test\n",
    "    sets, based on chain clusters. Note, train_fraction is \n",
    "    1 - valid_fraction - test_fraction.\n",
    "\n",
    "    Arguments:\n",
    "        data_df (pd.DataFrame):\n",
    "            DataFrame with the data.\n",
    "        chain_cluster_to_degree ((int -> int) dict):\n",
    "            Dictionary with the degree of each chain cluster.\n",
    "        chain_cluster_ids_column_name (str):\n",
    "            Name of the column with the chain cluster ids.\n",
    "        output_directory (str):\n",
    "            Directory to save the split data.\n",
    "        valid_fraction (optional, float):\n",
    "            Fraction of the data to use for validation.\n",
    "        test_fraction (optional, float):\n",
    "            Fraction of the data to use for testing.\n",
    "        max_valid_test_cluster_degree (optional, int):\n",
    "            Maximum degree of a cluster to be included in the validation and \n",
    "            test sets.\n",
    "        extra_test_cluster_ids (optional, list):\n",
    "            List of extra cluster ids to include in the test set.\n",
    "        seed (optional, int):\n",
    "            Seed for the random number generator.\n",
    "\n",
    "    Side Effects:\n",
    "        Saves the train, validation, and test dataframes to the output directory.\n",
    "        Saves the train, validation, and test chain cluster ids to the output directory.\n",
    "    \"\"\"\n",
    "    if seed == None:\n",
    "        seed_rng = np.random.default_rng()\n",
    "        seed = seed_rng.integers(0, 2 ** 32 - 1)\n",
    "\n",
    "    # Split the chain clusters into train, validation, and test sets.\n",
    "    train_cluster_ids, valid_cluster_ids, test_cluster_ids = \\\n",
    "        split_train_valid_test_clusters(chain_cluster_to_degree = chain_cluster_to_degree,\n",
    "                                        valid_fraction = valid_fraction,\n",
    "                                        test_fraction = test_fraction,\n",
    "                                        max_valid_test_cluster_degree = max_valid_test_cluster_degree,\n",
    "                                        extra_test_cluster_ids = extra_test_cluster_ids,\n",
    "                                        seed = seed)\n",
    "\n",
    "    # Split the entries in the dataset into train, validation, and test sets.\n",
    "    train_data_df, valid_data_df, test_data_df = \\\n",
    "        split_train_valid_test_entries(data_df,\n",
    "                                       chain_cluster_ids_column_name,\n",
    "                                       train_cluster_ids,\n",
    "                                       valid_cluster_ids,\n",
    "                                       test_cluster_ids)\n",
    "\n",
    "    # Evaluate how many DNA/RNA/protein-DNA/protein-RNA chains are in each set.\n",
    "    # Note, this only counts chains whose cluster id matches the cluster id\n",
    "    # split for the set. Since we cluster and split by cluster ids, but sample\n",
    "    # by complex, some chains from validation may end up in test, and some \n",
    "    # chains from training may end up in validation/test. \n",
    "    # NOTE: When evaluating the models, we should only look at chains that are \n",
    "    # in the correct set. The test/valid chains won't end up in training.\n",
    "    split_cluster_ids = {\n",
    "        \"train\": train_cluster_ids,\n",
    "        \"valid\": valid_cluster_ids,\n",
    "        \"test\": test_cluster_ids\n",
    "    }\n",
    "    split_dfs = {\n",
    "        \"train\": train_data_df,\n",
    "        \"valid\": valid_data_df,\n",
    "        \"test\": test_data_df\n",
    "    }\n",
    "    evaluate_train_valid_test_split(split_dfs)\n",
    "\n",
    "    # Save the train, validation, and test information.\n",
    "    save_train_valid_test_split(output_directory,\n",
    "                                chain_cluster_ids_column_name,\n",
    "                                data_df,\n",
    "                                split_dfs,\n",
    "                                split_cluster_ids,\n",
    "                                seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(all_datasets_output_directory):\n",
    "    shutil.rmtree(all_datasets_output_directory)\n",
    "os.makedirs(all_datasets_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes from the datasets.\n",
    "all_dfs = []\n",
    "for dataset_name in datasets_to_load:\n",
    "    dataset_directory = os.path.join(all_datasets_directory, dataset_name)\n",
    "    \n",
    "    preprocessing_output_path = os.path.join(dataset_directory, \"preprocessing_output.csv\")\n",
    "    preprocessing_output_df = pd.read_csv(preprocessing_output_path)\n",
    "\n",
    "    all_dfs.append(preprocessing_output_df)\n",
    "\n",
    "all_datasets_df = pd.concat(all_dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionaries for Auxillary Chain Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the family labels and chain clusters.\n",
    "all_protein_chain_clusters_df = pd.read_csv(protein_chain_clustering_path)\n",
    "all_nucleic_acid_chain_clusters_df = pd.read_csv(nucleic_acid_chain_clustering_path)\n",
    "all_protein_family_labels_df = pd.read_csv(protein_family_labeling_path)\n",
    "\n",
    "# Create a dictionary mapping protein chain sequence to protein cluster id.\n",
    "protein_sequence_to_chain_cluster_id = dict(zip(all_protein_chain_clusters_df[\"sequence\"], all_protein_chain_clusters_df[\"protein_chain_cluster_id\"]))\n",
    "\n",
    "# Create a dictionary mapping nucleic acid chain sequence to nucleic acid cluster id.\n",
    "nucleic_acid_sequence_to_chain_cluster_id = dict(zip(all_nucleic_acid_chain_clusters_df[\"sequence\"], all_nucleic_acid_chain_clusters_df[\"nucleic_acid_chain_cluster_id\"]))\n",
    "\n",
    "# Create dictionaries mapping protein sequence to pfam id, pfam description, interpro id, and interpro description.\n",
    "all_protein_family_labels_df_grouped = all_protein_family_labels_df.groupby(\"sequence\").agg({\"signature_accession\": list,\n",
    "                                                                                             \"signature_description\": list,\n",
    "                                                                                             \"interpro_accession\": list,\n",
    "                                                                                             \"interpro_description\": list})\n",
    "protein_sequence_to_pfam_ids = dict(zip(all_protein_family_labels_df_grouped.index, all_protein_family_labels_df_grouped[\"signature_accession\"]))\n",
    "protein_sequence_to_pfam_descriptions = dict(zip(all_protein_family_labels_df_grouped.index, all_protein_family_labels_df_grouped[\"signature_description\"]))\n",
    "protein_sequence_to_interpro_ids = dict(zip(all_protein_family_labels_df_grouped.index, all_protein_family_labels_df_grouped[\"interpro_accession\"]))\n",
    "protein_sequence_to_interpro_descriptions = dict(zip(all_protein_family_labels_df_grouped.index, all_protein_family_labels_df_grouped[\"interpro_description\"]))\n",
    "\n",
    "# Create dictionaries mapping pfam id to pfam description and interpro id to interpro description.\n",
    "pfam_id_to_pfam_description = dict()\n",
    "interpro_id_to_interpro_description = dict()\n",
    "for (pfam_id, \n",
    "     pfam_description, \n",
    "     interpro_id,\n",
    "     interpro_description) in zip(\n",
    "    all_protein_family_labels_df[\"signature_accession\"],\n",
    "    all_protein_family_labels_df[\"signature_description\"],\n",
    "    all_protein_family_labels_df[\"interpro_accession\"],\n",
    "    all_protein_family_labels_df[\"interpro_description\"]\n",
    "):\n",
    "    # pfam_id to pfam_description mapping.\n",
    "    if pfam_id not in pfam_id_to_pfam_description:\n",
    "        pfam_id_to_pfam_description[pfam_id] = pfam_description\n",
    "    else:\n",
    "        assert(pfam_id_to_pfam_description[pfam_id] == pfam_description)\n",
    "    \n",
    "    # interpro_id to interpro_description mapping.\n",
    "    if interpro_id not in interpro_id_to_interpro_description:\n",
    "        interpro_id_to_interpro_description[interpro_id] = interpro_description\n",
    "    else:\n",
    "        assert(interpro_id_to_interpro_description[interpro_id] == interpro_description)\n",
    "\n",
    "# Create a dictionary mapping protein chain cluster id to pfam ids, using\n",
    "# sequence as the intermediate.\n",
    "protein_chain_cluster_id_to_pfam_ids = dict()\n",
    "protein_chain_cluster_id_to_interpro_ids = dict()\n",
    "for sequence, protein_chain_cluster_id in protein_sequence_to_chain_cluster_id.items():\n",
    "    pfam_ids = protein_sequence_to_pfam_ids.get(sequence, [])\n",
    "    if protein_chain_cluster_id not in protein_chain_cluster_id_to_pfam_ids:\n",
    "        protein_chain_cluster_id_to_pfam_ids[protein_chain_cluster_id] = pfam_ids\n",
    "    else:\n",
    "        protein_chain_cluster_id_to_pfam_ids[protein_chain_cluster_id].extend(pfam_ids)\n",
    "\n",
    "    interpro_ids = protein_sequence_to_interpro_ids.get(sequence, [])\n",
    "    if protein_chain_cluster_id not in protein_chain_cluster_id_to_interpro_ids:\n",
    "        protein_chain_cluster_id_to_interpro_ids[protein_chain_cluster_id] = interpro_ids\n",
    "    else:\n",
    "        protein_chain_cluster_id_to_interpro_ids[protein_chain_cluster_id].extend(interpro_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some protein label/protein cluster dictionaries for use in specificity\n",
    "# dataset creation.\n",
    "pfam_id_to_pfam_description_path = os.path.join(all_datasets_output_directory, \"pfam_id_to_pfam_description.npy\")\n",
    "interpro_id_to_interpro_description_path = os.path.join(all_datasets_output_directory, \"interpro_id_to_interpro_description.npy\")\n",
    "protein_chain_cluster_id_to_pfam_ids_path = os.path.join(all_datasets_output_directory, \"protein_chain_cluster_id_to_pfam_ids.npy\")\n",
    "protein_chain_cluster_id_to_interpro_ids_path = os.path.join(all_datasets_output_directory, \"protein_chain_cluster_id_to_interpro_ids.npy\")\n",
    "\n",
    "np.save(pfam_id_to_pfam_description_path, pfam_id_to_pfam_description)\n",
    "np.save(interpro_id_to_interpro_description_path, interpro_id_to_interpro_description)\n",
    "np.save(protein_chain_cluster_id_to_pfam_ids_path, protein_chain_cluster_id_to_pfam_ids)\n",
    "np.save(protein_chain_cluster_id_to_interpro_ids_path, protein_chain_cluster_id_to_interpro_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Auxillary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sequence_with_auxillary_data(sequences_path, sequence_to_auxillary_data_dict, chain_types_to_consider, save_chain_types = False):\n",
    "    # Load the sequences.\n",
    "    sequences_df = pd.read_csv(sequences_path)    \n",
    "\n",
    "    # Compute the auxillary data to the sequences.\n",
    "    chain_types = []\n",
    "    per_sequence_auxillary_data = []\n",
    "    for chain_type, sequence in zip(sequences_df[\"chain_type\"], sequences_df[\"sequence\"]):\n",
    "        if chain_type in chain_types_to_consider and sequence in sequence_to_auxillary_data_dict:\n",
    "            auxillary_data = sequence_to_auxillary_data_dict[sequence]\n",
    "\n",
    "            # Save the auxillary data, flattening any lists.\n",
    "            if type(auxillary_data) == list:\n",
    "                per_sequence_auxillary_data.extend(auxillary_data)\n",
    "                # Save the chain type.\n",
    "                if save_chain_types:\n",
    "                    chain_types.extend([chain_type] * len(auxillary_data))\n",
    "            else:\n",
    "                per_sequence_auxillary_data.append(auxillary_data)\n",
    "                # Save the chain type.\n",
    "                if save_chain_types:\n",
    "                    chain_types.append(chain_type)\n",
    "    \n",
    "    return per_sequence_auxillary_data, chain_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain types, for use in the loading of auxillary data.\n",
    "protein_chain_types = [\n",
    "    \"polypeptide(L)\"\n",
    "]\n",
    "nucleic_acid_chain_types = [\n",
    "    \"polydeoxyribonucleotide/polyribonucleotide hybrid\", \n",
    "    \"polydeoxyribonucleotide\", \n",
    "    \"polyribonucleotide\"\n",
    "]\n",
    "\n",
    "# Information of the format auxillary_data_metadata[auxillary_data_name] = (sequence_to_auxillary_data_dict, chain_types_to_consider, save_chain_types)\n",
    "auxillary_data_metadata = {\n",
    "    \"protein_chain_cluster_ids\": (protein_sequence_to_chain_cluster_id, protein_chain_types, True),\n",
    "    \"nucleic_acid_chain_cluster_ids\": (nucleic_acid_sequence_to_chain_cluster_id, nucleic_acid_chain_types, True),\n",
    "    \"pfam_ids\": (protein_sequence_to_pfam_ids, protein_chain_types, False),\n",
    "    \"pfam_descriptions\": (protein_sequence_to_pfam_descriptions, protein_chain_types, False),\n",
    "    \"interpro_ids\": (protein_sequence_to_interpro_ids, protein_chain_types, False),\n",
    "    \"interpro_descriptions\": (protein_sequence_to_interpro_descriptions, protein_chain_types, False)\n",
    "}\n",
    "\n",
    "# For each entry, label the sequences with auxillary data.\n",
    "auxillary_data_dict = {}\n",
    "for sequences_path in all_datasets_df[\"sequences_path\"]:\n",
    "    # Load the sequences.\n",
    "    sequences_df = pd.read_csv(sequences_path)   \n",
    "\n",
    "    for auxillary_data_name in auxillary_data_metadata:\n",
    "        sequence_to_auxillary_data_dict, chain_types_to_consider, save_chain_types = auxillary_data_metadata[auxillary_data_name]\n",
    "        \n",
    "        per_sequence_auxillary_data = []\n",
    "        per_sequence_chain_types = []\n",
    "        for chain_type, sequence in zip(sequences_df[\"chain_type\"], sequences_df[\"sequence\"]):\n",
    "            if chain_type in chain_types_to_consider and sequence in sequence_to_auxillary_data_dict:\n",
    "                auxillary_data = sequence_to_auxillary_data_dict[sequence]\n",
    "\n",
    "                # Save the auxillary data, flattening any lists.\n",
    "                if type(auxillary_data) == list:\n",
    "                    per_sequence_auxillary_data.extend(auxillary_data)\n",
    "                    per_sequence_chain_types.extend([chain_type] * len(auxillary_data))\n",
    "                else:\n",
    "                    per_sequence_auxillary_data.append(auxillary_data)\n",
    "                    per_sequence_chain_types.append(chain_type)\n",
    "        \n",
    "        # Make the overall lists if they do not exist.\n",
    "        if auxillary_data_name not in auxillary_data_dict:\n",
    "            auxillary_data_dict[auxillary_data_name] = []\n",
    "            if save_chain_types:\n",
    "                auxillary_data_dict[auxillary_data_name + \"_chain_types\"] = []\n",
    "\n",
    "        # Record the auxillary data for the entry.\n",
    "        auxillary_data_dict[auxillary_data_name].append(per_sequence_auxillary_data)\n",
    "        if save_chain_types:\n",
    "            auxillary_data_dict[auxillary_data_name + \"_chain_types\"].append(per_sequence_chain_types)\n",
    "\n",
    "all_datasets_df[\"protein_chain_cluster_ids\"] = auxillary_data_dict[\"protein_chain_cluster_ids\"]\n",
    "all_datasets_df[\"protein_chain_cluster_ids_chain_types\"] = auxillary_data_dict[\"protein_chain_cluster_ids_chain_types\"]\n",
    "all_datasets_df[\"nucleic_acid_chain_cluster_ids\"] = auxillary_data_dict[\"nucleic_acid_chain_cluster_ids\"]\n",
    "all_datasets_df[\"nucleic_acid_chain_cluster_ids_chain_types\"] = auxillary_data_dict[\"nucleic_acid_chain_cluster_ids_chain_types\"]\n",
    "all_datasets_df[\"pfam_ids\"] = auxillary_data_dict[\"pfam_ids\"]\n",
    "all_datasets_df[\"pfam_descriptions\"] = auxillary_data_dict[\"pfam_descriptions\"]\n",
    "all_datasets_df[\"interpro_ids\"] = auxillary_data_dict[\"interpro_ids\"]\n",
    "all_datasets_df[\"interpro_descriptions\"] = auxillary_data_dict[\"interpro_descriptions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Any Entries with No Protein or Nucleic Acid Chain IDs\n",
    "\n",
    "This will only occur if all chains in the complex were too short for clustering; also, these short sequences are not included for determining sampling probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_df = all_datasets_df[((all_datasets_df.protein_chain_cluster_ids.map(len) > 0) | (all_datasets_df.nucleic_acid_chain_cluster_ids.map(len) > 0))]\n",
    "all_datasets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregate dataset.\n",
    "all_datasets_df.to_csv(all_datasets_output_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_df = pd.read_csv(all_datasets_output_path, \n",
    "                              converters = {column: ast.literal_eval for column in list_columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit to RCSB CIF NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_dataset_df = all_datasets_df[all_datasets_df[\"dataset_name\"] == \"rcsb_cif_na\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Chain Cluster Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the degrees of the protein and nucleic acid chain clusters.\n",
    "design_protein_chain_cluster_to_degree = compute_chain_cluster_degrees(design_dataset_df, \"protein_chain_cluster_ids\")\n",
    "design_nucleic_acid_chain_cluster_to_degree = compute_chain_cluster_degrees(design_dataset_df, \"nucleic_acid_chain_cluster_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sampling Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean 1 / (1 + degree) across protein and nucleic acid chain clusters.\n",
    "design_dataset_df[\"sampling_probability\"] = design_dataset_df.apply(lambda row: np.mean(1 / (1 + np.array(row[\"protein_chain_cluster_degrees\"] + row[\"nucleic_acid_chain_cluster_degrees\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into All/Train/Valid/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the distribution of the degrees of the protein chain clusters.\n",
    "print(len(design_protein_chain_cluster_to_degree))\n",
    "plt.hist(design_protein_chain_cluster_to_degree.values(), bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the distribution of the degrees of the nucleic acid chain clusters.\n",
    "print(len(design_nucleic_acid_chain_cluster_to_degree))\n",
    "plt.hist(design_nucleic_acid_chain_cluster_to_degree.values(), bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some psuedoknots as an extra test set.\n",
    "pseudoknot_pdb_ids = [\"7kd1\", \"3q3z\", \"4plx\", \"2m8k\", \"4oqu\", \"7kga\", \"1drz\", \"7qr4\", \"2miy\", \"4znp\"]\n",
    "\n",
    "pseudoknot_nucleic_acid_chain_cluster_ids = set()\n",
    "for pseudoknot_pdb_id in pseudoknot_pdb_ids:\n",
    "    pseudoknot_nucleic_acid_chain_cluster_ids.update(design_dataset_df[design_dataset_df[\"id\"] == pseudoknot_pdb_id][\"nucleic_acid_chain_cluster_ids\"].values[0])\n",
    "\n",
    "print(pseudoknot_nucleic_acid_chain_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_test_split(data_df = design_dataset_df,\n",
    "                       chain_cluster_to_degree = design_nucleic_acid_chain_cluster_to_degree,\n",
    "                       chain_cluster_ids_column_name = \"nucleic_acid_chain_cluster_ids\",\n",
    "                       output_directory = design_dataset_output_directory,\n",
    "                       valid_fraction = 0.1,\n",
    "                       test_fraction = 0.1,\n",
    "                       max_valid_test_cluster_degree = 25,\n",
    "                       extra_test_cluster_ids = pseudoknot_nucleic_acid_chain_cluster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specificity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_df = pd.read_csv(all_datasets_output_path, \n",
    "                              converters = {column: ast.literal_eval for column in list_columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_dataset_df = all_datasets_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Chain Cluster Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the degrees of the protein and nucleic acid chain clusters.\n",
    "specificity_protein_chain_cluster_to_degree = compute_chain_cluster_degrees(specificity_dataset_df, \"protein_chain_cluster_ids\")\n",
    "specificity_nucleic_acid_chain_cluster_to_degree = compute_chain_cluster_degrees(specificity_dataset_df, \"nucleic_acid_chain_cluster_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sampling Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean 1 / (1 + degree) across protein and nucleic acid chain clusters.\n",
    "specificity_dataset_df[\"sampling_probability\"] = specificity_dataset_df.apply(lambda row: np.mean(1 / (1 + np.array(row[\"protein_chain_cluster_degrees\"] + row[\"nucleic_acid_chain_cluster_degrees\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into All/Train/Valid/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the distribution of the degrees of the protein chain clusters.\n",
    "print(len(specificity_protein_chain_cluster_to_degree))\n",
    "plt.hist(specificity_protein_chain_cluster_to_degree.values(), bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the distribution of the degrees of the nucleic acid chain clusters.\n",
    "print(len(specificity_nucleic_acid_chain_cluster_to_degree))\n",
    "plt.hist(specificity_nucleic_acid_chain_cluster_to_degree.values(), bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of the pfam labels to the number of entries that they occur in\n",
    "# with ppms, with ppms from crystal, and with ppms from distillation.\n",
    "pfam_description_to_num_entries_with_ppm = {}\n",
    "pfam_description_to_num_entries_with_ppm_from_crystal = {}\n",
    "pfam_description_to_num_entries_with_ppm_from_distillation = {}\n",
    "for pfam_descriptions, ppm_paths, dataset_name in zip(\n",
    "    specificity_dataset_df[\"pfam_descriptions\"], \n",
    "    specificity_dataset_df[\"ppm_paths\"],\n",
    "    specificity_dataset_df[\"dataset_name\"]\n",
    "):\n",
    "    if len(ppm_paths) > 0:\n",
    "        for pfam_description in set(pfam_descriptions):\n",
    "            pfam_description_to_num_entries_with_ppm[pfam_description] = pfam_description_to_num_entries_with_ppm.get(pfam_description, 0) + 1\n",
    "\n",
    "            if dataset_name == \"rcsb_cif_na\":\n",
    "                pfam_description_to_num_entries_with_ppm_from_crystal[pfam_description] = pfam_description_to_num_entries_with_ppm_from_crystal.get(pfam_description, 0) + 1\n",
    "            elif dataset_name == \"rf2na_distillation_cis_bp\" or dataset_name == \"rf2na_distillation_transfac\":\n",
    "                pfam_description_to_num_entries_with_ppm_from_distillation[pfam_description] = pfam_description_to_num_entries_with_ppm_from_distillation.get(pfam_description, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for the number of entries with PPMs, with PPMs from crystal,\n",
    "# and with PPMs from distillation.\n",
    "plt.hist(pfam_description_to_num_entries_with_ppm.values(), bins = 1000)\n",
    "plt.show()\n",
    "print(sorted(pfam_description_to_num_entries_with_ppm.items(), key = lambda x: x[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pfam_description_to_num_entries_with_ppm_from_crystal.values(), bins = 1000)\n",
    "plt.show()\n",
    "print(sorted(pfam_description_to_num_entries_with_ppm_from_crystal.items(), key = lambda x: x[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pfam_description_to_num_entries_with_ppm_from_distillation.values(), bins = 1000)\n",
    "plt.show()\n",
    "print(sorted(pfam_description_to_num_entries_with_ppm_from_distillation.items(), key = lambda x: x[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_test_split(data_df = specificity_dataset_df,\n",
    "                       chain_cluster_to_degree = specificity_protein_chain_cluster_to_degree,\n",
    "                       chain_cluster_ids_column_name = \"protein_chain_cluster_ids\",\n",
    "                       output_directory = specificity_dataset_output_directory,\n",
    "                       valid_fraction = 0.1,\n",
    "                       test_fraction = 0.1,\n",
    "                       max_valid_test_cluster_degree = 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
